# 📅 2025-07-01 TIL - 머신러닝 방법론 정리 (3-1 ~ 3-3)

---

## 🤖 머신러닝 방법론 분류 (3-1)

### 📌 지도학습 (Supervised Learning)
- 입력값 `x`와 정답 `y`를 함께 주고 학습
- 목적: 주어진 입력에 대해 정확한 출력 예측
- 예시: 가격 예측, 이미지 분류, 스팸 메일 분류

### 📌 비지도학습 (Unsupervised Learning)
- 정답 `y` 없이 입력값 `x`만으로 학습
- 목적: 데이터 간 구조, 패턴, 군집 찾기
- 예시: 군집화(Clustering), 차원 축소(PCA)

### 🤖 강화학습 (Reinforcement Learning) (간단 소개)
- 환경과 상호작용하며 보상을 최대화하는 방향으로 학습

---

## 📈 회귀 문제 정리 (3-2)

### 📌 회귀(Regression)란?
- 출력값 `y`가 연속적인 수치형 변수일 때 사용하는 문제 유형
- 예시: 키 예측, 집값 예측, 온도 예측

### 📐 선형 회귀 모델
- 기본 형태: `y = ax + b`
- `a`: 기울기 (slope), `b`: y절편 (bias)
- 목표: 실제값과 예측값의 차이(오차)를 최소화하는 `a`, `b`를 찾는 것

### 📉 손실 함수 (Loss Function)
- MSE (Mean Squared Error):  
  \( MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \)
- 오차를 제곱하여 평균, 값이 작을수록 모델이 잘 예측함

### 🧮 최적화 방법
- **해석적 해법**: 수학 공식으로 정답을 바로 계산 (ex. 정규 방정식)
- **수치적 해법**: 반복적으로 정답 근사 (ex. 경사 하강법, Gradient Descent)

### 📊 상관관계 vs 인과관계
- **상관관계**: 두 변수의 동시 변화 경향성 (ex. 얼음 판매량 ↔ 온도)
- **인과관계**: 하나의 변화가 다른 하나에 직접적 영향
- 상관계수 \( r \in [-1, 1] \): 절댓값이 클수록 강한 상관

---

## 🧠 분류 문제 정리 (3-3)

### 📌 분류(Classification)란?
- 출력값 `y`가 이산적인 범주형(label)일 때 사용
- 예시: 스팸/정상 메일, 개/고양이 이미지 분류

### 🔸 이진 분류 (Binary Classification)
- 정답이 두 가지 (0 or 1)
- 예: 질병 유무, 합격/불합격

### 🔸 다중 분류 (Multiclass Classification)
- 정답이 여러 클래스 중 하나 (0,1,2,...)
- 예: 숫자 이미지 분류 (MNIST: 0~9)

### 📈 로지스틱 회귀 (Logistic Regression)
- 선형 회귀 + 시그모이드(로지스틱) 함수
- 출력값: 0 ~ 1 사이 확률
- 예측값이 0.5 이상이면 1, 아니면 0으로 분류
- 손실함수: Binary Cross Entropy (BCE)

### 🔣 One-Hot Encoding
- 다중 분류에서 정답을 벡터로 표현
- 예: 클래스 2 → [0, 0, 1, 0, 0]

---

## 🌳 다양한 분류 모델 소개

| 모델 | 설명 |
|------|------|
| k-NN | 가장 가까운 k개 이웃을 기반으로 분류 |
| 결정트리 | 조건 기반으로 데이터를 나누는 트리 |
| 랜덤 포레스트 | 여러 결정트리를 앙상블 |
| SVM | 최대 마진 경계를 찾는 분류기, 커널 사용 가능 |
| Softmax Regression | 다중 클래스 확률 분포 출력 |

---

## 🧾 오늘의 한 줄 요약

> 머신러닝 문제는 크게 **회귀**와 **분류**로 나뉘며,  
> 입력/출력의 형태에 따라 적절한 모델과 손실함수를 선택하는 것이 핵심이다.
