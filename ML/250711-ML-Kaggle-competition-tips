# 📅 2025-07-11 TIL - 캐글 실전 대회 팁 정리

## ✅ 1. 실험 전 준비사항

### 🐛 디버깅 모드
- 실험 환경, 코드 오류 확인용
- 전체 데이터 대신 **샘플 데이터** 또는 **작은 모델**, **축소된 하이퍼파라미터**로 체크

### 🧪 시드(seed) 고정
- 같은 코드에서 결과가 달라지는 것을 방지
- 모든 모듈에서 시드 고정 필요 (ex. `numpy`, `torch`, `random` 등)

### 📝 실험 기록
- 실험 조건별 성능 기록 (ex. Notion, Google Sheets)
- 한번에 여러 조건 변경 ❌ → **한 번에 하나씩 변경** 추천

---

## 🔁 2. 앙상블 (Ensemble)

### 📊 데이터 측면 - KFold 앙상블
- 데이터 분할 기반 모델 → 예측값 평균

### 🧠 모델 측면
- 서로 다른 모델을 조합 (예: LightGBM + Catboost)
- **Stacking**: 모델 예측 결과를 새로운 입력값으로 사용

### 🎲 랜덤성 측면
- Seed만 다르게 하여 모델 다변화

---

## 📦 3. 추가 데이터 활용

### 🧪 Pseudo Labeling
- 평가 데이터에 모델 예측 결과로 라벨 생성 → 학습 데이터로 활용

**학습 흐름**
1. 모델 학습
2. 평가 데이터 예측
3. 학습 데이터 + 예측 데이터 합치기
4. 새로운 모델 학습

### 🌐 외부 데이터 활용
- 주로 **Pseudo Labeling** 기법으로 통합

---

## 📈 4. 분석 도구

### ⚙️ 자동 EDA 도구
- [`Dataprep.eda`](https://eda-ai-lab.tistory.com/655): EDA 자동화

### 📊 실험 기록 및 시각화 도구
- [`Weights & Biases`](https://docs.wandb.ai): 실험 로그, 시각화, 하이퍼파라미터 탐색

---

## 🧪 5. 실전 사례 - Recsys 2023

### 🗂 데이터 구성
- 사용자 방문 로그 기반 다변량 데이터
- 목표: `is_installed` 여부 분류

### 📉 문제점 분석
- **Covariate Shift**: 시간 흐름에 따라 데이터 분포 변화
  - 해결: 특정 시점 기준 분할, 높은 AUC 변수 제거

### 🛠 Feature Engineering
- Frequency Encoding, CatBoost Encoding (주의: **미래 정보 제외**)
- 수치형 컬럼 간 **상관계수 분석**을 통해 중복 제거

### 🤖 모델 선택
- 성능 비교 결과: `LightGBM > Catboost > XGBoost > DNN`

---

## 🧠 핵심 요약

| 구분 | 핵심 내용 |
|------|-----------|
| 실험 전 | 디버깅 / 시드 고정 / 실험 기록 필수 |
| 앙상블 | 데이터 / 모델 / 시드 다양성 활용 |
| 추가데이터 | Pseudo Labeling, 외부 데이터 전략적으로 사용 |
| 분석 도구 | 자동화 도구 적극 활용 (EDA, 실험 기록) |
| 실전 사례 | 데이터 분포 변화(Covariate Shift)에 유의해야 |

